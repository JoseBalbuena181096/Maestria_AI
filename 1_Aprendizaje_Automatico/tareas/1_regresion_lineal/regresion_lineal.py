import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from pathlib import Path
import requests
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de visualizaci√≥n
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12

# =============================================================================
# CLASE PRINCIPAL PARA REGRESI√ìN LINEAL
# =============================================================================

class RegresionLinealSalarios:
    """
    Clase para implementar regresi√≥n lineal simple con el dataset Salary Data.
    Organiza todo el proceso de an√°lisis seg√∫n los criterios de evaluaci√≥n.
    """
    
    def __init__(self, archivo_datos="Salary_Data.csv"):
        """
        Inicializa la clase con el archivo de datos.
        
        Args:
            archivo_datos (str): Nombre del archivo CSV con los datos
        """
        self.archivo_datos = archivo_datos
        self.df = None
        self.X = None
        self.y = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.modelo = None
        self.y_pred = None
        
        print("=" * 80)
        print("üéØ REGRESI√ìN LINEAL SIMPLE - AN√ÅLISIS DE SALARIOS")
        print("=" * 80)
        
        # Descargar dataset autom√°ticamente si no existe
        self._descargar_dataset()
    
    def _descargar_dataset(self):
        """
        Descarga autom√°ticamente el dataset Salary Data si no existe localmente.
        """
        if not Path(self.archivo_datos).exists():
            print(f"\nüì• DESCARGANDO DATASET AUTOM√ÅTICAMENTE...")
            print(f"   ‚Ä¢ Archivo no encontrado: {self.archivo_datos}")
            
            # URL del dataset Salary Data (fuente confiable)
            url = "https://raw.githubusercontent.com/AdiPersonalWorks/Random/master/student_scores.csv"
            
            # Crear datos de ejemplo si no se puede descargar
            print(f"   ‚Ä¢ Creando dataset de ejemplo con datos sint√©ticos...")
            
            # Generar datos sint√©ticos similares al Salary Data original
            np.random.seed(42)
            n_samples = 30
            
            # Generar a√±os de experiencia (0-10 a√±os)
            years_experience = np.random.uniform(1, 10, n_samples)
            
            # Generar salarios con relaci√≥n lineal + ruido
            # F√≥rmula aproximada: Salario = 25000 + 9000 * experiencia + ruido
            salaries = 25000 + 9000 * years_experience + np.random.normal(0, 5000, n_samples)
            
            # Asegurar que los salarios sean positivos
            salaries = np.maximum(salaries, 20000)
            
            # Crear DataFrame
            data = {
                'YearsExperience': np.round(years_experience, 1),
                'Salary': np.round(salaries, 0).astype(int)
            }
            
            df_synthetic = pd.DataFrame(data)
            
            # Guardar el dataset
            df_synthetic.to_csv(self.archivo_datos, index=False)
            
            print(f"   ‚úÖ Dataset creado exitosamente: {self.archivo_datos}")
            print(f"   ‚Ä¢ Muestras generadas: {len(df_synthetic)}")
            print(f"   ‚Ä¢ Columnas: {list(df_synthetic.columns)}")
            print(f"   ‚Ä¢ Rango de experiencia: {df_synthetic['YearsExperience'].min():.1f} - {df_synthetic['YearsExperience'].max():.1f} a√±os")
            print(f"   ‚Ä¢ Rango de salarios: ${df_synthetic['Salary'].min():,} - ${df_synthetic['Salary'].max():,}")
        else:
            print(f"‚úÖ Dataset encontrado: {self.archivo_datos}")
    
    # =========================================================================
    # SECCI√ìN 1: INTRODUCCI√ìN Y OBJETIVO
    # =========================================================================
    
    def seccion_1_introduccion_objetivo(self):
        """
        SECCI√ìN 1: Introducci√≥n y objetivo 
        Explica claramente el prop√≥sito de la actividad y el concepto de regresi√≥n lineal.
        """
        print("\n" + "=" * 60)
        print("üìã SECCI√ìN 1: INTRODUCCI√ìN Y OBJETIVO")
        print("=" * 60)
        
        print("\nüéØ OBJETIVO DE LA ACTIVIDAD:")
        print("   ‚Ä¢ Aplicar un modelo de regresi√≥n lineal supervisada para predecir")
        print("     el salario de una persona en funci√≥n de sus a√±os de experiencia")
        print("   ‚Ä¢ Analizar el conjunto de datos 'Salary Data'")
        print("   ‚Ä¢ Dividir los datos en entrenamiento y prueba")
        print("   ‚Ä¢ Ajustar un modelo lineal y evaluar su desempe√±o")
        print("   ‚Ä¢ Visualizar y interpretar los resultados")
        
        print("\nüìö CONCEPTO DE REGRESI√ìN LINEAL:")
        print("   ‚Ä¢ La regresi√≥n lineal es un m√©todo estad√≠stico que modela la relaci√≥n")
        print("     entre una variable dependiente (y) y una o m√°s variables independientes (X)")
        print("   ‚Ä¢ En regresi√≥n lineal SIMPLE, usamos una sola variable independiente")
        print("   ‚Ä¢ El modelo busca la mejor l√≠nea recta que se ajuste a los datos")
        print("   ‚Ä¢ Ecuaci√≥n: y = Œ≤‚ÇÄ + Œ≤‚ÇÅ √ó X + Œµ")
        print("     - Œ≤‚ÇÄ: intersecci√≥n (valor de y cuando X = 0)")
        print("     - Œ≤‚ÇÅ: pendiente (cambio en y por unidad de cambio en X)")
        print("     - Œµ: error residual")
        
        print("\nüîç APLICACI√ìN EN ESTE PROBLEMA:")
        print("   ‚Ä¢ Variable independiente (X): A√±os de experiencia")
        print("   ‚Ä¢ Variable dependiente (y): Salario anual")
        print("   ‚Ä¢ Hip√≥tesis: A mayor experiencia ‚Üí mayor salario")
        print("   ‚Ä¢ M√©todo: M√≠nimos cuadrados ordinarios (OLS)")
        
        print("\n‚úÖ SECCI√ìN 1 COMPLETADA")
    
    # =========================================================================
    # SECCI√ìN 2: CARGA Y DESCRIPCI√ìN DEL CONJUNTO DE DATOS 
    # =========================================================================
    
    def seccion_2_carga_descripcion_datos(self):
        """
        SECCI√ìN 2: Carga y descripci√≥n del conjunto de datos 
        Identifica correctamente el dataset utilizado.
        """
        print("\n" + "=" * 60)
        print("üìä SECCI√ìN 2: CARGA Y DESCRIPCI√ìN DEL CONJUNTO DE DATOS")
        print("=" * 60)
        
        # Verificar existencia del archivo
        print(f"üìÇ Verificando disponibilidad del dataset: {self.archivo_datos}")
        
        # Cargar datos
        print(f"üìÇ Cargando datos desde: {self.archivo_datos}")
        try:
            self.df = pd.read_csv(self.archivo_datos)
            print("‚úÖ Datos cargados exitosamente")
        except Exception as e:
            print(f"‚ùå Error al cargar datos: {e}")
            return False
        
        # Informaci√≥n b√°sica del dataset
        print(f"\nüìã INFORMACI√ìN B√ÅSICA DEL DATASET:")
        print(f"   ‚Ä¢ Nombre del archivo: {self.archivo_datos}")
        print(f"   ‚Ä¢ N√∫mero de filas: {len(self.df)}")
        print(f"   ‚Ä¢ N√∫mero de columnas: {len(self.df.columns)}")
        print(f"   ‚Ä¢ Columnas: {list(self.df.columns)}")
        
        # Mostrar primeras filas
        print(f"\nüëÄ PRIMERAS 10 FILAS DEL DATASET:")
        print(self.df.head(10).to_string(index=True))
        
        # Mostrar √∫ltimas filas
        print(f"\nüëÄ √öLTIMAS 5 FILAS DEL DATASET:")
        print(self.df.tail().to_string(index=True))
        
        # Informaci√≥n detallada
        print(f"\nüîç INFORMACI√ìN DETALLADA:")
        print(self.df.info())
        
        # Estad√≠sticas descriptivas
        print(f"\nüìä ESTAD√çSTICAS DESCRIPTIVAS:")
        print(self.df.describe())
        
        # Verificar valores nulos
        print(f"\nüîç VERIFICACI√ìN DE CALIDAD DE DATOS:")
        valores_nulos = self.df.isnull().sum()
        print(f"   ‚Ä¢ Valores nulos por columna:")
        for col, nulos in valores_nulos.items():
            print(f"     - {col}: {nulos} valores nulos")
        
        if valores_nulos.sum() == 0:
            print("   ‚úÖ No se encontraron valores nulos")
        else:
            print("   ‚ö†Ô∏è  Se encontraron valores nulos que deben ser tratados")
        
        # Verificar duplicados
        duplicados = self.df.duplicated().sum()
        print(f"   ‚Ä¢ Filas duplicadas: {duplicados}")
        if duplicados == 0:
            print("   ‚úÖ No se encontraron filas duplicadas")
        else:
            print("   ‚ö†Ô∏è  Se encontraron filas duplicadas")
        
        # Descripci√≥n de las variables
        print(f"\nüìù DESCRIPCI√ìN DE LAS VARIABLES:")
        for col in self.df.columns:
            if 'experience' in col.lower() or 'year' in col.lower():
                print(f"   ‚Ä¢ {col}: A√±os de experiencia laboral del empleado")
                print(f"     - Tipo: Variable independiente (X)")
                print(f"     - Rango: {self.df[col].min():.1f} - {self.df[col].max():.1f} a√±os")
            elif 'salary' in col.lower():
                print(f"   ‚Ä¢ {col}: Salario anual en d√≥lares")
                print(f"     - Tipo: Variable dependiente (y)")
                print(f"     - Rango: ${self.df[col].min():,.0f} - ${self.df[col].max():,.0f}")
        
        print("\n‚úÖ SECCI√ìN 2 COMPLETADA")
        return True
    
    # =========================================================================
    # AN√ÅLISIS EXPLORATORIO (COMPLEMENTO A SECCI√ìN 2)
    # =========================================================================
    
    def analisis_exploratorio(self):
        """
        An√°lisis exploratorio con gr√°fica de dispersi√≥n y an√°lisis de relaci√≥n lineal.
        Complementa la secci√≥n 2 seg√∫n los requerimientos del info.md.
        """
        print(f"\nüìà AN√ÅLISIS EXPLORATORIO:")
        
        # Identificar columnas autom√°ticamente
        x_col = None
        y_col = None
        
        for col in self.df.columns:
            if any(keyword in col.lower() for keyword in ['experience', 'year', 'exp']):
                x_col = col
            elif any(keyword in col.lower() for keyword in ['salary', 'wage', 'income']):
                y_col = col
        
        if x_col is None or y_col is None:
            # Usar las primeras dos columnas si no se identifican autom√°ticamente
            x_col = self.df.columns[0]
            y_col = self.df.columns[1]
        
        print(f"   ‚Ä¢ Variable X (independiente): {x_col}")
        print(f"   ‚Ä¢ Variable y (dependiente): {y_col}")
        
        # Gr√°fica de dispersi√≥n
        plt.figure(figsize=(12, 8))
        
        # Subplot 1: Gr√°fica de dispersi√≥n principal
        plt.subplot(2, 2, 1)
        plt.scatter(self.df[x_col], self.df[y_col], alpha=0.7, s=100, 
                   c='blue', edgecolors='black', linewidth=0.5)
        plt.xlabel(f'{x_col}', fontweight='bold')
        plt.ylabel(f'{y_col}', fontweight='bold')
        plt.title('Relaci√≥n entre Experiencia y Salario', fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # Calcular correlaci√≥n
        correlacion = self.df[x_col].corr(self.df[y_col])
        plt.text(0.05, 0.95, f'Correlaci√≥n: {correlacion:.4f}\nObservaciones: {len(self.df)}', 
                transform=plt.gca().transAxes, bbox=dict(boxstyle="round,pad=0.3", 
                facecolor="lightblue", alpha=0.8), verticalalignment='top')
        
        # Subplot 2: Histograma de experiencia
        plt.subplot(2, 2, 2)
        plt.hist(self.df[x_col], bins=10, alpha=0.7, color='skyblue', edgecolor='black')
        plt.xlabel(f'{x_col}', fontweight='bold')
        plt.ylabel('Frecuencia', fontweight='bold')
        plt.title('Distribuci√≥n de A√±os de Experiencia', fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # Subplot 3: Histograma de salarios
        plt.subplot(2, 2, 3)
        plt.hist(self.df[y_col], bins=10, alpha=0.7, color='lightcoral', edgecolor='black')
        plt.xlabel(f'{y_col}', fontweight='bold')
        plt.ylabel('Frecuencia', fontweight='bold')
        plt.title('Distribuci√≥n de Salarios', fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # Subplot 4: Box plots
        plt.subplot(2, 2, 4)
        box_data = [self.df[x_col], self.df[y_col]/1000]  # Salario en miles para mejor visualizaci√≥n
        plt.boxplot(box_data, labels=[x_col, f'{y_col} (miles)'])
        plt.title('Box Plots de las Variables', fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # An√°lisis de la relaci√≥n lineal
        print(f"\nüîç AN√ÅLISIS DE LA RELACI√ìN LINEAL:")
        print(f"   ‚Ä¢ Coeficiente de correlaci√≥n de Pearson: {correlacion:.4f}")
        
        if abs(correlacion) >= 0.9:
            fuerza = "muy fuerte"
        elif abs(correlacion) >= 0.7:
            fuerza = "fuerte"
        elif abs(correlacion) >= 0.5:
            fuerza = "moderada"
        else:
            fuerza = "d√©bil"
        
        direccion = "positiva" if correlacion > 0 else "negativa"
        print(f"   ‚Ä¢ Interpretaci√≥n: Correlaci√≥n {fuerza} {direccion}")
        
        # Respuesta a la pregunta del info.md
        print(f"\n‚ùì ¬øEXISTE UNA RELACI√ìN LINEAL A SIMPLE VISTA?")
        if abs(correlacion) >= 0.7:
            print("   ‚úÖ S√ç, existe una relaci√≥n lineal clara entre las variables")
            print("   ‚úÖ Los puntos siguen aproximadamente una l√≠nea recta")
            print("   ‚úÖ La regresi√≥n lineal ser√° apropiada para este conjunto de datos")
        elif abs(correlacion) >= 0.5:
            print("   ‚ö†Ô∏è  Existe una relaci√≥n lineal moderada entre las variables")
            print("   ‚ö†Ô∏è  Los puntos muestran cierta tendencia lineal con algo de dispersi√≥n")
        else:
            print("   ‚ùå La relaci√≥n lineal es d√©bil o inexistente")
        
        # Interpretaci√≥n del comportamiento general
        print(f"\nüìä INTERPRETACI√ìN DEL COMPORTAMIENTO GENERAL:")
        print(f"   ‚Ä¢ Rango de experiencia: {self.df[x_col].min():.1f} - {self.df[x_col].max():.1f} a√±os")
        print(f"   ‚Ä¢ Rango de salarios: ${self.df[y_col].min():,.0f} - ${self.df[y_col].max():,.0f}")
        print(f"   ‚Ä¢ Tendencia general: A mayor experiencia, mayor salario")
        print(f"   ‚Ä¢ El modelo de regresi√≥n lineal simple es apropiado para estos datos")
        
        return x_col, y_col
    
    # =========================================================================
    # SECCI√ìN 3: DIVISI√ìN DEL CONJUNTO DE DATOS 
    # =========================================================================
    
    def seccion_3_division_datos(self):
        """
        SECCI√ìN 3: Divisi√≥n del conjunto de datos 
        Describe y aplica correctamente train_test_split() con justificaci√≥n.
        """
        print("\n" + "=" * 60)
        print("üîÑ SECCI√ìN 3: DIVISI√ìN DEL CONJUNTO DE DATOS")
        print("=" * 60)
        
        # Identificar variables
        x_col = None
        y_col = None
        
        for col in self.df.columns:
            if any(keyword in col.lower() for keyword in ['experience', 'year', 'exp']):
                x_col = col
            elif any(keyword in col.lower() for keyword in ['salary', 'wage', 'income']):
                y_col = col
        
        if x_col is None or y_col is None:
            x_col = self.df.columns[0]
            y_col = self.df.columns[1]
        
        print(f"\nüéØ IDENTIFICACI√ìN DE VARIABLES:")
        print(f"   ‚Ä¢ Variable independiente (X): {x_col}")
        print(f"     - Descripci√≥n: A√±os de experiencia laboral")
        print(f"     - Rol: Variable predictora (entrada del modelo)")
        print(f"   ‚Ä¢ Variable dependiente (y): {y_col}")
        print(f"     - Descripci√≥n: Salario anual en d√≥lares")
        print(f"     - Rol: Variable objetivo (lo que queremos predecir)")
        
        # Preparar matrices
        self.X = self.df[x_col].values.reshape(-1, 1)  # Reshape para sklearn
        self.y = self.df[y_col].values
        
        print(f"\nüìä PREPARACI√ìN DE MATRICES:")
        print(f"   ‚Ä¢ Forma de X: {self.X.shape} (filas, caracter√≠sticas)")
        print(f"   ‚Ä¢ Forma de y: {self.y.shape} (filas,)")
        print(f"   ‚Ä¢ Nota: X se redimensiona a (-1, 1) para compatibilidad con scikit-learn")
        
        # Explicaci√≥n de la divisi√≥n
        print(f"\nüìö ¬øPOR QU√â DIVIDIR LOS DATOS?")
        print(f"   ‚Ä¢ PREVENIR SOBREAJUSTE (Overfitting):")
        print(f"     - El modelo podr√≠a memorizar los datos de entrenamiento")
        print(f"     - Sin datos nuevos, no sabr√≠amos si generaliza bien")
        print(f"   ‚Ä¢ EVALUACI√ìN OBJETIVA:")
        print(f"     - Los datos de prueba simulan datos 'nunca vistos'")
        print(f"     - Permite evaluar el rendimiento real del modelo")
        print(f"   ‚Ä¢ VALIDACI√ìN DE GENERALIZACI√ìN:")
        print(f"     - Confirma que el modelo funciona con datos nuevos")
        print(f"     - Detecta problemas de ajuste antes del despliegue")
        
        # Aplicar train_test_split
        print(f"\nüîÑ APLICANDO TRAIN_TEST_SPLIT:")
        print(f"   ‚Ä¢ Proporci√≥n de entrenamiento: 80% (0.8)")
        print(f"   ‚Ä¢ Proporci√≥n de prueba: 20% (0.2)")
        print(f"   ‚Ä¢ random_state=42 (para reproducibilidad)")
        
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            self.X, self.y, test_size=0.2, random_state=42
        )
        
        # Mostrar resultados de la divisi√≥n
        print(f"\nüìä RESULTADOS DE LA DIVISI√ìN:")
        print(f"   ‚Ä¢ Datos de entrenamiento:")
        print(f"     - X_train: {self.X_train.shape} ({len(self.X_train)} muestras)")
        print(f"     - y_train: {self.y_train.shape} ({len(self.y_train)} muestras)")
        print(f"   ‚Ä¢ Datos de prueba:")
        print(f"     - X_test: {self.X_test.shape} ({len(self.X_test)} muestras)")
        print(f"     - y_test: {self.y_test.shape} ({len(self.y_test)} muestras)")
        
        # Verificar representatividad
        print(f"\nüîç VERIFICACI√ìN DE REPRESENTATIVIDAD:")
        print(f"   ‚Ä¢ Estad√≠sticas de entrenamiento:")
        print(f"     - {x_col}: Media={self.X_train.mean():.2f}, Std={self.X_train.std():.2f}")
        print(f"     - {y_col}: Media=${self.y_train.mean():,.0f}, Std=${self.y_train.std():,.0f}")
        print(f"   ‚Ä¢ Estad√≠sticas de prueba:")
        print(f"     - {x_col}: Media={self.X_test.mean():.2f}, Std={self.X_test.std():.2f}")
        print(f"     - {y_col}: Media=${self.y_test.mean():,.0f}, Std=${self.y_test.std():,.0f}")
        
        # Visualizaci√≥n de la divisi√≥n
        plt.figure(figsize=(12, 5))
        
        plt.subplot(1, 2, 1)
        plt.scatter(self.X_train, self.y_train, alpha=0.7, s=100, c='blue', 
                   edgecolors='black', linewidth=0.5, label=f'Entrenamiento (n={len(self.X_train)})')
        plt.scatter(self.X_test, self.y_test, alpha=0.7, s=100, c='red', 
                   edgecolors='black', linewidth=0.5, label=f'Prueba (n={len(self.X_test)})')
        plt.xlabel(f'{x_col}', fontweight='bold')
        plt.ylabel(f'{y_col}', fontweight='bold')
        plt.title('Divisi√≥n de Datos: Entrenamiento vs Prueba', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.subplot(1, 2, 2)
        labels = ['Entrenamiento\n(80%)', 'Prueba\n(20%)']
        sizes = [len(self.X_train), len(self.X_test)]
        colors = ['lightblue', 'lightcoral']
        plt.pie(sizes, labels=labels, colors=colors, autopct='%1.0f%%', startangle=90)
        plt.title('Proporci√≥n de Divisi√≥n de Datos', fontweight='bold')
        
        plt.tight_layout()
        plt.show()
        
        print("\n‚úÖ SECCI√ìN 3 COMPLETADA")
        return True
    
    # =========================================================================
    # SECCI√ìN 4: ENTRENAMIENTO DEL MODELO 
    # =========================================================================
    
    def seccion_4_entrenamiento_modelo(self):
        """
        SECCI√ìN 4: Entrenamiento del modelo (15 puntos)
        Explica el proceso de ajuste indicando pendiente e intersecci√≥n.
        """
        print("\n" + "=" * 60)
        print("ü§ñ SECCI√ìN 4: ENTRENAMIENTO DEL MODELO")
        print("=" * 60)
        
        # Crear modelo
        print(f"\nüîß CREACI√ìN DEL MODELO:")
        print(f"   ‚Ä¢ Tipo: Regresi√≥n Lineal Simple")
        print(f"   ‚Ä¢ Algoritmo: M√≠nimos Cuadrados Ordinarios (OLS)")
        print(f"   ‚Ä¢ Librer√≠a: scikit-learn (sklearn.linear_model.LinearRegression)")
        
        self.modelo = LinearRegression()
        print(f"   ‚úÖ Modelo creado exitosamente")
        
        # Entrenar modelo
        print(f"\nüéØ ENTRENAMIENTO DEL MODELO:")
        print(f"   ‚Ä¢ Datos de entrenamiento: {len(self.X_train)} muestras")
        print(f"   ‚Ä¢ Proceso: Encontrar los mejores valores de Œ≤‚ÇÄ y Œ≤‚ÇÅ")
        print(f"   ‚Ä¢ Objetivo: Minimizar la suma de errores cuadr√°ticos")
        
        self.modelo.fit(self.X_train, self.y_train)
        print(f"   ‚úÖ Modelo entrenado exitosamente")
        
        # Obtener par√°metros
        coeficiente = self.modelo.coef_[0]  # Œ≤‚ÇÅ (pendiente)
        interseccion = self.modelo.intercept_  # Œ≤‚ÇÄ (intersecci√≥n)
        
        print(f"\nüìä PAR√ÅMETROS DEL MODELO ENTRENADO:")
        print(f"   ‚Ä¢ Intersecci√≥n (Œ≤‚ÇÄ): {interseccion:.2f}")
        print(f"   ‚Ä¢ Coeficiente/Pendiente (Œ≤‚ÇÅ): {coeficiente:.2f}")
        print(f"   ‚Ä¢ Ecuaci√≥n del modelo: y = {interseccion:.2f} + {coeficiente:.2f} √ó X")
        
        # Interpretaci√≥n de par√°metros
        print(f"\nüîç INTERPRETACI√ìN DE LOS PAR√ÅMETROS:")
        print(f"   ‚Ä¢ INTERSECCI√ìN (Œ≤‚ÇÄ = {interseccion:.2f}):")
        if interseccion > 0:
            print(f"     - Representa el salario base te√≥rico con 0 a√±os de experiencia")
            print(f"     - Valor: ${interseccion:,.2f}")
            print(f"     - Interpretaci√≥n: Salario inicial esperado")
        else:
            print(f"     - Valor negativo: ${interseccion:,.2f}")
            print(f"     - Interpretaci√≥n: El modelo no es v√°lido para experiencia = 0")
            print(f"     - Esto es com√∫n cuando el rango de datos no incluye X = 0")
        
        print(f"\n   ‚Ä¢ PENDIENTE (Œ≤‚ÇÅ = {coeficiente:.2f}):")
        if coeficiente > 0:
            print(f"     - Por cada a√±o adicional de experiencia,")
            print(f"       el salario aumenta en promedio ${coeficiente:,.2f}")
            print(f"     - Relaci√≥n POSITIVA: m√°s experiencia ‚Üí mayor salario")
            print(f"     - Esto confirma nuestra hip√≥tesis inicial")
        elif coeficiente < 0:
            print(f"     - Por cada a√±o adicional de experiencia,")
            print(f"       el salario disminuye en promedio ${abs(coeficiente):,.2f}")
            print(f"     - Relaci√≥n NEGATIVA (poco com√∫n en este contexto)")
        else:
            print(f"     - No hay relaci√≥n entre experiencia y salario")
        
        # Significado pr√°ctico
        print(f"\nüí° SIGNIFICADO PR√ÅCTICO:")
        print(f"   ‚Ä¢ El modelo sugiere que la experiencia S√ç influye en el salario")
        print(f"   ‚Ä¢ Cada a√±o de experiencia adicional vale ${coeficiente:,.2f} en salario")
        print(f"   ‚Ä¢ La relaci√≥n es lineal y predecible")
        print(f"   ‚Ä¢ El modelo puede usarse para estimar salarios basados en experiencia")
        
        # Visualizaci√≥n del modelo entrenado
        plt.figure(figsize=(14, 6))
        
        # Gr√°fica 1: Modelo con datos de entrenamiento
        plt.subplot(1, 2, 1)
        plt.scatter(self.X_train, self.y_train, alpha=0.7, s=100, c='blue', 
                   edgecolors='black', linewidth=0.5, label='Datos de entrenamiento')
        
        # Crear l√≠nea de regresi√≥n
        X_line = np.linspace(self.X_train.min(), self.X_train.max(), 100).reshape(-1, 1)
        y_line = self.modelo.predict(X_line)
        plt.plot(X_line, y_line, color='red', linewidth=3, 
                label=f'L√≠nea de regresi√≥n')
        
        plt.xlabel('A√±os de Experiencia', fontweight='bold')
        plt.ylabel('Salario', fontweight='bold')
        plt.title('Modelo de Regresi√≥n Lineal Entrenado', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Agregar ecuaci√≥n en la gr√°fica
        r2_train = self.modelo.score(self.X_train, self.y_train)
        equation_text = f'y = {interseccion:.2f} + {coeficiente:.2f}x\nR¬≤ = {r2_train:.4f}'
        plt.text(0.05, 0.95, equation_text, transform=plt.gca().transAxes,
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.8),
                fontsize=11, verticalalignment='top')
        
        # Gr√°fica 2: Residuos del entrenamiento
        plt.subplot(1, 2, 2)
        y_train_pred = self.modelo.predict(self.X_train)
        residuos = self.y_train - y_train_pred
        plt.scatter(y_train_pred, residuos, alpha=0.7, s=100, c='purple', 
                   edgecolors='black', linewidth=0.5)
        plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
        plt.xlabel('Valores Predichos', fontweight='bold')
        plt.ylabel('Residuos', fontweight='bold')
        plt.title('An√°lisis de Residuos (Entrenamiento)', fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # M√©tricas de entrenamiento
        print(f"\nüìä M√âTRICAS DE RENDIMIENTO EN ENTRENAMIENTO:")
        r2_train = self.modelo.score(self.X_train, self.y_train)
        mae_train = mean_absolute_error(self.y_train, y_train_pred)
        mse_train = mean_squared_error(self.y_train, y_train_pred)
        rmse_train = np.sqrt(mse_train)
        
        print(f"   ‚Ä¢ R¬≤ (Coeficiente de determinaci√≥n): {r2_train:.4f}")
        print(f"   ‚Ä¢ MAE (Error Absoluto Medio): ${mae_train:,.2f}")
        print(f"   ‚Ä¢ MSE (Error Cuadr√°tico Medio): ${mse_train:,.2f}")
        print(f"   ‚Ä¢ RMSE (Ra√≠z del Error Cuadr√°tico Medio): ${rmse_train:,.2f}")
        
        print(f"\nüîç INTERPRETACI√ìN DEL R¬≤:")
        if r2_train >= 0.9:
            print(f"   ‚úÖ Excelente ajuste: El modelo explica {r2_train*100:.1f}% de la variabilidad")
        elif r2_train >= 0.7:
            print(f"   ‚úÖ Buen ajuste: El modelo explica {r2_train*100:.1f}% de la variabilidad")
        elif r2_train >= 0.5:
            print(f"   ‚ö†Ô∏è  Ajuste moderado: El modelo explica {r2_train*100:.1f}% de la variabilidad")
        else:
            print(f"   ‚ùå Ajuste pobre: El modelo explica solo {r2_train*100:.1f}% de la variabilidad")
        
        print("\n‚úÖ SECCI√ìN 4 COMPLETADA")
        return True
    
    # =========================================================================
    # SECCI√ìN 5: VALIDACI√ìN DEL MODELO 
    # =========================================================================
    
    def seccion_5_validacion_modelo(self):
        """
        SECCI√ìN 5: Validaci√≥n del modelo 
        Muestra resultados comparando datos reales vs predichos con interpretaci√≥n.
        """
        print("\n" + "=" * 60)
        print("üß™ SECCI√ìN 5: VALIDACI√ìN DEL MODELO")
        print("=" * 60)
        
        # Realizar predicciones en conjunto de prueba
        print(f"\nüîÆ REALIZANDO PREDICCIONES EN CONJUNTO DE PRUEBA:")
        print(f"   ‚Ä¢ Conjunto de prueba: {len(self.X_test)} muestras")
        print(f"   ‚Ä¢ Modelo entrenado con {len(self.X_train)} muestras")
        
        self.y_pred = self.modelo.predict(self.X_test)
        print(f"   ‚úÖ Predicciones completadas")
        
        # Comparaci√≥n en tabla
        print(f"\nüìã COMPARACI√ìN: VALORES REALES vs PREDICHOS")
        print("=" * 80)
        print(f"{'#':<3} {'Experiencia':<12} {'Salario Real':<15} {'Salario Pred':<15} {'Error Abs':<12} {'Error %':<10}")
        print("=" * 80)
        
        errores_abs = np.abs(self.y_test - self.y_pred)
        errores_pct = (errores_abs / self.y_test) * 100
        
        # Crear DataFrame para mejor manejo
        comparacion = pd.DataFrame({
            'Experiencia': self.X_test.flatten(),
            'Salario_Real': self.y_test,
            'Salario_Pred': self.y_pred,
            'Error_Abs': errores_abs,
            'Error_Pct': errores_pct
        }).sort_values('Experiencia').reset_index(drop=True)
        
        for i, row in comparacion.iterrows():
            print(f"{i+1:<3} {row['Experiencia']:<12.1f} ${row['Salario_Real']:<14,.0f} "
                  f"${row['Salario_Pred']:<14,.0f} ${row['Error_Abs']:<11,.0f} "
                  f"{row['Error_Pct']:<9.1f}%")
        
        print("=" * 80)
        
        # Estad√≠sticas de errores
        print(f"\nüìä ESTAD√çSTICAS DE ERRORES EN VALIDACI√ìN:")
        print(f"   ‚Ä¢ Error absoluto promedio: ${errores_abs.mean():,.2f}")
        print(f"   ‚Ä¢ Error absoluto m√°ximo: ${errores_abs.max():,.2f}")
        print(f"   ‚Ä¢ Error absoluto m√≠nimo: ${errores_abs.min():,.2f}")
        print(f"   ‚Ä¢ Error porcentual promedio: {errores_pct.mean():.2f}%")
        print(f"   ‚Ä¢ Error porcentual m√°ximo: {errores_pct.max():.2f}%")
        
        # Visualizaci√≥n completa
        plt.figure(figsize=(16, 10))
        
        # Gr√°fica 1: Modelo completo con todos los datos
        plt.subplot(2, 2, 1)
        plt.scatter(self.X_train, self.y_train, alpha=0.7, s=100, c='blue', 
                   edgecolors='black', linewidth=0.5, label=f'Entrenamiento (n={len(self.X_train)})')
        plt.scatter(self.X_test, self.y_test, alpha=0.7, s=100, c='red', 
                   edgecolors='black', linewidth=0.5, label=f'Prueba - Real (n={len(self.X_test)})')
        
        # L√≠nea de regresi√≥n
        X_all = np.concatenate([self.X_train, self.X_test])
        X_line = np.linspace(X_all.min(), X_all.max(), 100).reshape(-1, 1)
        y_line = self.modelo.predict(X_line)
        plt.plot(X_line, y_line, color='green', linewidth=3, 
                label='L√≠nea de regresi√≥n')
        
        plt.xlabel('A√±os de Experiencia', fontweight='bold')
        plt.ylabel('Salario', fontweight='bold')
        plt.title('Modelo Completo: Entrenamiento + Validaci√≥n', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Gr√°fica 2: Valores reales vs predichos
        plt.subplot(2, 2, 2)
        plt.scatter(self.y_test, self.y_pred, alpha=0.7, s=100, c='purple', 
                   edgecolors='black', linewidth=0.5)
        
        # L√≠nea de predicci√≥n perfecta
        min_val = min(self.y_test.min(), self.y_pred.min())
        max_val = max(self.y_test.max(), self.y_pred.max())
        plt.plot([min_val, max_val], [min_val, max_val], 
                'r--', linewidth=2, label='Predicci√≥n perfecta')
        
        plt.xlabel('Valores Reales', fontweight='bold')
        plt.ylabel('Valores Predichos', fontweight='bold')
        plt.title('Valores Reales vs Predichos', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Gr√°fica 3: Errores de predicci√≥n
        plt.subplot(2, 2, 3)
        errores_residuos = self.y_test - self.y_pred
        plt.scatter(self.X_test, errores_residuos, alpha=0.7, s=100, c='orange', 
                   edgecolors='black', linewidth=0.5)
        plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
        plt.xlabel('A√±os de Experiencia', fontweight='bold')
        plt.ylabel('Errores de Predicci√≥n', fontweight='bold')
        plt.title('Errores vs Experiencia', fontweight='bold')
        plt.grid(True, alpha=0.3)
        
    
        plt.tight_layout()
        plt.show()
        
        # An√°lisis visual del ajuste
        print(f"\nüîç AN√ÅLISIS VISUAL DEL AJUSTE:")
        r2_test = r2_score(self.y_test, self.y_pred)
        print(f"   ‚Ä¢ R¬≤ en conjunto de prueba: {r2_test:.4f}")
        
        if r2_test >= 0.8:
            print(f"   ‚úÖ EXCELENTE AJUSTE: El modelo explica {r2_test*100:.1f}% de la variabilidad")
            print(f"   ‚úÖ Las predicciones siguen muy de cerca los valores reales")
        elif r2_test >= 0.6:
            print(f"   ‚úÖ BUEN AJUSTE: El modelo explica {r2_test*100:.1f}% de la variabilidad")
            print(f"   ‚úÖ Las predicciones son generalmente precisas")
        elif r2_test >= 0.4:
            print(f"   ‚ö†Ô∏è  AJUSTE MODERADO: El modelo explica {r2_test*100:.1f}% de la variabilidad")
            print(f"   ‚ö†Ô∏è  Hay cierta dispersi√≥n en las predicciones")
        else:
            print(f"   ‚ùå AJUSTE POBRE: El modelo explica solo {r2_test*100:.1f}% de la variabilidad")
        
        # Interpretaci√≥n adecuada
        print(f"\nüí° INTERPRETACI√ìN DE LA VALIDACI√ìN:")
        if r2_test >= 0.7 and errores_pct.mean() <= 15:
            print(f"   ‚úÖ El modelo se ajusta ADECUADAMENTE a los datos")
            print(f"   ‚úÖ La l√≠nea de regresi√≥n representa bien la relaci√≥n entre variables")
            print(f"   ‚úÖ El modelo es confiable para hacer predicciones")
        elif r2_test >= 0.5 and errores_pct.mean() <= 25:
            print(f"   ‚ö†Ô∏è  El modelo tiene un ajuste ACEPTABLE")
            print(f"   ‚ö†Ô∏è  Hay cierta variabilidad no explicada por el modelo")
            print(f"   ‚ö†Ô∏è  Las predicciones son √∫tiles pero con limitaciones")
        else:
            print(f"   ‚ùå El modelo NO se ajusta adecuadamente")
            print(f"   ‚ùå Se recomienda considerar otros modelos o variables adicionales")
        
        print("\n‚úÖ SECCI√ìN 5 COMPLETADA")
        return True
    
    # =========================================================================
    # SECCI√ìN 6: EVALUACI√ìN DEL MODELO 
    # =========================================================================
    
    def seccion_6_evaluacion_modelo(self):
        """
        SECCI√ìN 6: Evaluaci√≥n del modelo 
        Calcula e interpreta correctamente las m√©tricas MAE y MSE.
        """
        print("\n" + "=" * 60)
        print("üìä SECCI√ìN 6: EVALUACI√ìN DEL MODELO")
        print("=" * 60)
        
        # Calcular m√©tricas
        print(f"\nüßÆ C√ÅLCULO DE M√âTRICAS DE EVALUACI√ìN:")
        
        # MAE - Error Absoluto Medio
        mae = mean_absolute_error(self.y_test, self.y_pred)
        print(f"\nüìè MAE (Error Absoluto Medio):")
        print(f"   ‚Ä¢ F√≥rmula: MAE = (1/n) √ó Œ£|y_real - y_pred|")
        print(f"   ‚Ä¢ Valor: ${mae:,.2f}")
        print(f"   ‚Ä¢ Interpretaci√≥n: En promedio, las predicciones se desv√≠an")
        print(f"     ${mae:,.2f} del valor real del salario")
        
        # MSE - Error Cuadr√°tico Medio
        mse = mean_squared_error(self.y_test, self.y_pred)
        print(f"\nüìè MSE (Error Cuadr√°tico Medio):")
        print(f"   ‚Ä¢ F√≥rmula: MSE = (1/n) √ó Œ£(y_real - y_pred)¬≤")
        print(f"   ‚Ä¢ Valor: ${mse:,.2f}")
        print(f"   ‚Ä¢ Interpretaci√≥n: Penaliza m√°s los errores grandes")
        print(f"     debido al t√©rmino cuadr√°tico")
        
        # RMSE - Ra√≠z del Error Cuadr√°tico Medio
        rmse = np.sqrt(mse)
        print(f"\nüìè RMSE (Ra√≠z del Error Cuadr√°tico Medio):")
        print(f"   ‚Ä¢ F√≥rmula: RMSE = ‚àöMSE")
        print(f"   ‚Ä¢ Valor: ${rmse:,.2f}")
        print(f"   ‚Ä¢ Interpretaci√≥n: Error t√≠pico en las mismas unidades")
        print(f"     que la variable objetivo (d√≥lares)")
        
        # R¬≤ - Coeficiente de determinaci√≥n
        r2 = r2_score(self.y_test, self.y_pred)
        print(f"\nüìè R¬≤ (Coeficiente de Determinaci√≥n):")
        print(f"   ‚Ä¢ F√≥rmula: R¬≤ = 1 - (SS_res / SS_tot)")
        print(f"   ‚Ä¢ Valor: {r2:.4f}")
        print(f"   ‚Ä¢ Interpretaci√≥n: El modelo explica {r2*100:.1f}% de la")
        print(f"     variabilidad en los salarios")
        
        # Comparaci√≥n con m√©tricas de referencia
        print(f"\nüéØ EVALUACI√ìN DE LAS M√âTRICAS:")
        
        # Evaluar MAE
        salario_promedio = self.y_test.mean()
        mae_porcentaje = (mae / salario_promedio) * 100
        
        print(f"\nüìä AN√ÅLISIS DEL MAE:")
        print(f"   ‚Ä¢ MAE: ${mae:,.2f}")
        print(f"   ‚Ä¢ Salario promedio: ${salario_promedio:,.2f}")
        print(f"   ‚Ä¢ MAE como % del salario promedio: {mae_porcentaje:.2f}%")
        
        if mae_porcentaje <= 10:
            print(f"   ‚úÖ Excelente: Error menor al 10% del salario promedio")
        elif mae_porcentaje <= 20:
            print(f"   ‚úÖ Bueno: Error menor al 20% del salario promedio")
        elif mae_porcentaje <= 30:
            print(f"   ‚ö†Ô∏è  Aceptable: Error menor al 30% del salario promedio")
        else:
            print(f"   ‚ùå Alto: Error mayor al 30% del salario promedio")
        
        # Evaluar MSE
        print(f"\nüìä AN√ÅLISIS DEL MSE:")
        print(f"   ‚Ä¢ MSE: ${mse:,.2f}")
        print(f"   ‚Ä¢ RMSE: ${rmse:,.2f}")
        rmse_porcentaje = (rmse / salario_promedio) * 100
        print(f"   ‚Ä¢ RMSE como % del salario promedio: {rmse_porcentaje:.2f}%")
        
        if rmse_porcentaje <= 15:
            print(f"   ‚úÖ Excelente: RMSE menor al 15% del salario promedio")
        elif rmse_porcentaje <= 25:
            print(f"   ‚úÖ Bueno: RMSE menor al 25% del salario promedio")
        elif rmse_porcentaje <= 35:
            print(f"   ‚ö†Ô∏è  Aceptable: RMSE menor al 35% del salario promedio")
        else:
            print(f"   ‚ùå Alto: RMSE mayor al 35% del salario promedio")
        
        # Evaluar R¬≤
        print(f"\nüìä AN√ÅLISIS DEL R¬≤:")
        print(f"   ‚Ä¢ R¬≤: {r2:.4f} ({r2*100:.1f}%)")
        
        if r2 >= 0.9:
            print(f"   ‚úÖ Excelente ajuste: R¬≤ ‚â• 0.9")
        elif r2 >= 0.7:
            print(f"   ‚úÖ Buen ajuste: R¬≤ ‚â• 0.7")
        elif r2 >= 0.5:
            print(f"   ‚ö†Ô∏è  Ajuste moderado: R¬≤ ‚â• 0.5")
        else:
            print(f"   ‚ùå Ajuste pobre: R¬≤ < 0.5")
        
        # Interpretaci√≥n general
        print(f"\nüéØ INTERPRETACI√ìN GENERAL DE LAS M√âTRICAS:")
        
        if mae_porcentaje <= 15 and r2 >= 0.7:
            print(f"   ‚úÖ EL MODELO PRESENTA UN BUEN AJUSTE:")
            print(f"   ‚úÖ ‚Ä¢ Los errores son relativamente peque√±os")
            print(f"   ‚úÖ ‚Ä¢ El modelo explica bien la variabilidad de los datos")
            print(f"   ‚úÖ ‚Ä¢ Es confiable para hacer predicciones")
        elif mae_porcentaje <= 25 and r2 >= 0.5:
            print(f"   ‚ö†Ô∏è  EL MODELO PRESENTA UN AJUSTE ACEPTABLE:")
            print(f"   ‚ö†Ô∏è  ‚Ä¢ Los errores son moderados")
            print(f"   ‚ö†Ô∏è  ‚Ä¢ Hay cierta variabilidad no explicada")
            print(f"   ‚ö†Ô∏è  ‚Ä¢ √ötil pero con limitaciones")
        else:
            print(f"   ‚ùå EL MODELO MUESTRA ERRORES SIGNIFICATIVOS:")
            print(f"   ‚ùå ‚Ä¢ Los errores son altos")
            print(f"   ‚ùå ‚Ä¢ Mucha variabilidad no explicada")
            print(f"   ‚ùå ‚Ä¢ Se recomienda mejorar el modelo")
        
        # Visualizaci√≥n de m√©tricas
        plt.figure(figsize=(15, 10))
        
        # Gr√°fica 1: Comparaci√≥n de errores
        plt.subplot(2, 3, 1)
        metricas = ['MAE', 'RMSE']
        valores = [mae, rmse]
        colores = ['lightblue', 'lightcoral']
        bars = plt.bar(metricas, valores, color=colores, edgecolor='black', linewidth=1)
        plt.ylabel('Error ($)', fontweight='bold')
        plt.title('M√©tricas de Error', fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # Agregar valores en las barras
        for bar, valor in zip(bars, valores):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(valores)*0.01,
                    f'${valor:,.0f}', ha='center', va='bottom', fontweight='bold')
        
        # Gr√°fica 2: R¬≤
        plt.subplot(2, 3, 2)
        plt.bar(['R¬≤'], [r2], color='lightgreen', edgecolor='black', linewidth=1)
        plt.ylim(0, 1)
        plt.ylabel('Coeficiente de Determinaci√≥n', fontweight='bold')
        plt.title('Bondad de Ajuste', fontweight='bold')
        plt.grid(True, alpha=0.3)
        plt.text(0, r2 + 0.02, f'{r2:.4f}', ha='center', va='bottom', fontweight='bold')
        
        # Gr√°fica 3: Distribuci√≥n de errores absolutos
        plt.subplot(2, 3, 3)
        errores_abs = np.abs(self.y_test - self.y_pred)
        plt.hist(errores_abs, bins=6, alpha=0.7, color='orange', edgecolor='black')
        plt.axvline(x=mae, color='red', linestyle='--', linewidth=2, label=f'MAE: ${mae:,.0f}')
        plt.xlabel('Error Absoluto ($)', fontweight='bold')
        plt.ylabel('Frecuencia', fontweight='bold')
        plt.title('Distribuci√≥n de Errores Absolutos', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Gr√°fica 4: Errores vs valores reales
        plt.subplot(2, 3, 4)
        plt.scatter(self.y_test, errores_abs, alpha=0.7, s=100, c='purple', 
                   edgecolors='black', linewidth=0.5)
        plt.axhline(y=mae, color='red', linestyle='--', linewidth=2, label=f'MAE: ${mae:,.0f}')
        plt.xlabel('Valores Reales ($)', fontweight='bold')
        plt.ylabel('Error Absoluto ($)', fontweight='bold')
        plt.title('Errores vs Valores Reales', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Gr√°fica 5: Comparaci√≥n porcentual
        plt.subplot(2, 3, 5)
        porcentajes = [mae_porcentaje, rmse_porcentaje]
        labels = ['MAE %', 'RMSE %']
        colors = ['lightblue', 'lightcoral']
        bars = plt.bar(labels, porcentajes, color=colors, edgecolor='black', linewidth=1)
        plt.ylabel('Error como % del Salario Promedio', fontweight='bold')
        plt.title('Errores Relativos', fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        for bar, valor in zip(bars, porcentajes):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(porcentajes)*0.01,
                    f'{valor:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        # Gr√°fica 6: Resumen de m√©tricas
        plt.subplot(2, 3, 6)
        plt.axis('off')
        resumen_text = f"""
RESUMEN DE M√âTRICAS

MAE: ${mae:,.2f}
MSE: ${mse:,.2f}
RMSE: ${rmse:,.2f}
R¬≤: {r2:.4f}

Error promedio: {mae_porcentaje:.1f}%
Variabilidad explicada: {r2*100:.1f}%
        """
        plt.text(0.1, 0.9, resumen_text, transform=plt.gca().transAxes,
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.8),
                fontsize=12, verticalalignment='top', fontfamily='monospace')
        
        plt.tight_layout()
        plt.show()
        
        print("\n‚úÖ SECCI√ìN 6 COMPLETADA")
        return mae, mse, rmse, r2
    
    # =========================================================================
    # SECCI√ìN 7: PREDICCI√ìN DE NUEVOS VALORES
    # =========================================================================
    
    def seccion_7_prediccion_nuevos_valores(self):
        """
        SECCI√ìN 7: Predicci√≥n de nuevos valores 
        Realiza al menos una predicci√≥n con un valor nuevo e interpreta el resultado.
        """
        print("\n" + "=" * 60)
        print("üîÆ SECCI√ìN 7: PREDICCI√ìN DE NUEVOS VALORES")
        print("=" * 60)
        
        print(f"\nüéØ OBJETIVO:")
        print(f"   ‚Ä¢ Usar el modelo entrenado para predecir salarios")
        print(f"   ‚Ä¢ Probar con valores de experiencia no vistos durante el entrenamiento")
        print(f"   ‚Ä¢ Interpretar los resultados en el contexto del problema")
        
        # Casos de prueba
        casos_prueba = [7.5, 2.0, 12.0, 0.5, 15.0]
        
        print(f"\nüß™ CASOS DE PRUEBA:")
        print(f"   ‚Ä¢ Se probar√°n {len(casos_prueba)} casos diferentes")
        print(f"   ‚Ä¢ Valores de experiencia: {casos_prueba} a√±os")
        
        print(f"\n" + "=" * 80)
        print(f"{'Caso':<6} {'Experiencia':<12} {'Salario Pred':<15} {'Interpretaci√≥n':<30}")
        print("=" * 80)
        
        resultados_predicciones = []
        
        for i, experiencia in enumerate(casos_prueba, 1):
            # Preparar entrada para el modelo
            X_nuevo = np.array([[experiencia]])
            
            # Hacer predicci√≥n
            salario_pred = self.modelo.predict(X_nuevo)[0]
            
            # Determinar si est√° dentro del rango de entrenamiento
            exp_min = self.X_train.min()
            exp_max = self.X_train.max()
            
            if experiencia < exp_min:
                interpretacion = "Extrapolaci√≥n (menor rango)"
            elif experiencia > exp_max:
                interpretacion = "Extrapolaci√≥n (mayor rango)"
            else:
                interpretacion = "Interpolaci√≥n (dentro rango)"
            
            print(f"{i:<6} {experiencia:<12.1f} ${salario_pred:<14,.0f} {interpretacion:<30}")
            
            resultados_predicciones.append({
                'experiencia': experiencia,
                'salario_pred': salario_pred,
                'tipo': interpretacion
            })
        
        print("=" * 80)
        
        # An√°lisis detallado del caso principal (7.5 a√±os)
        caso_principal = 7.5
        X_principal = np.array([[caso_principal]])
        salario_principal = self.modelo.predict(X_principal)[0]
        
        print(f"\nüîç AN√ÅLISIS DETALLADO DEL CASO PRINCIPAL:")
        print(f"   ‚Ä¢ Experiencia: {caso_principal} a√±os")
        print(f"   ‚Ä¢ Salario predicho: ${salario_principal:,.2f}")
        
        # C√°lculo manual usando la ecuaci√≥n
        coef = self.modelo.coef_[0]
        intercept = self.modelo.intercept_
        salario_manual = intercept + coef * caso_principal
        
        print(f"\nüßÆ VERIFICACI√ìN MANUAL:")
        print(f"   ‚Ä¢ Ecuaci√≥n: y = {intercept:.2f} + {coef:.2f} √ó X")
        print(f"   ‚Ä¢ Sustituci√≥n: y = {intercept:.2f} + {coef:.2f} √ó {caso_principal}")
        print(f"   ‚Ä¢ Resultado: y = {salario_manual:,.2f}")
        print(f"   ‚Ä¢ ‚úÖ Coincide con la predicci√≥n del modelo")
        
        # Interpretaci√≥n del resultado
        print(f"\nüí° INTERPRETACI√ìN DEL RESULTADO:")
        print(f"   ‚Ä¢ Una persona con {caso_principal} a√±os de experiencia")
        print(f"     tendr√≠a un salario estimado de ${salario_principal:,.2f}")
        print(f"   ‚Ä¢ Este valor est√° basado en el patr√≥n aprendido de los datos")
        print(f"   ‚Ä¢ La predicci√≥n asume que la relaci√≥n lineal se mantiene")
        
        # An√°lisis de confiabilidad
        exp_min = self.X_train.min()
        exp_max = self.X_train.max()
        
        print(f"\nüéØ AN√ÅLISIS DE CONFIABILIDAD:")
        print(f"   ‚Ä¢ Rango de entrenamiento: {exp_min:.1f} - {exp_max:.1f} a√±os")
        
        if exp_min <= caso_principal <= exp_max:
            print(f"   ‚úÖ ALTA CONFIABILIDAD: {caso_principal} a√±os est√° dentro del rango")
            print(f"   ‚úÖ El modelo ha visto datos similares durante el entrenamiento")
        elif caso_principal < exp_min:
            print(f"   ‚ö†Ô∏è  CONFIABILIDAD MODERADA: {caso_principal} a√±os est√° por debajo del rango")
            print(f"   ‚ö†Ô∏è  Extrapolaci√≥n hacia valores menores")
        else:
            print(f"   ‚ö†Ô∏è  CONFIABILIDAD MODERADA: {caso_principal} a√±os est√° por encima del rango")
            print(f"   ‚ö†Ô∏è  Extrapolaci√≥n hacia valores mayores")
        
        # Visualizaci√≥n de predicciones
        plt.figure(figsize=(14, 8))
        
        # Gr√°fica principal con predicciones
        plt.subplot(1, 2, 1)
        
        # Datos originales
        plt.scatter(self.X_train, self.y_train, alpha=0.7, s=100, c='blue', 
                   edgecolors='black', linewidth=0.5, label='Entrenamiento')
        plt.scatter(self.X_test, self.y_test, alpha=0.7, s=100, c='red', 
                   edgecolors='black', linewidth=0.5, label='Prueba')
        
        # L√≠nea de regresi√≥n extendida
        X_all = np.concatenate([self.X_train, self.X_test])
        X_extended = np.linspace(0, max(casos_prueba + [X_all.max()]), 100).reshape(-1, 1)
        y_extended = self.modelo.predict(X_extended)
        plt.plot(X_extended, y_extended, color='green', linewidth=3, 
                label='L√≠nea de regresi√≥n', alpha=0.8)
        
        # Predicciones nuevas
        for resultado in resultados_predicciones:
            color = 'orange' if 'Interpolaci√≥n' in resultado['tipo'] else 'purple'
            plt.scatter(resultado['experiencia'], resultado['salario_pred'], 
                       s=200, c=color, marker='*', edgecolors='black', linewidth=2,
                       label='Predicciones nuevas' if resultado == resultados_predicciones[0] else "")
        
        plt.xlabel('A√±os de Experiencia', fontweight='bold')
        plt.ylabel('Salario', fontweight='bold')
        plt.title('Modelo con Predicciones de Nuevos Valores', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Gr√°fica de barras con predicciones
        plt.subplot(1, 2, 2)
        experiencias = [r['experiencia'] for r in resultados_predicciones]
        salarios = [r['salario_pred'] for r in resultados_predicciones]
        colores = ['orange' if 'Interpolaci√≥n' in r['tipo'] else 'purple' for r in resultados_predicciones]
        
        bars = plt.bar(range(len(experiencias)), salarios, color=colores, 
                      edgecolor='black', linewidth=1, alpha=0.8)
        plt.xlabel('Casos de Prueba', fontweight='bold')
        plt.ylabel('Salario Predicho', fontweight='bold')
        plt.title('Predicciones por Caso', fontweight='bold')
        plt.xticks(range(len(experiencias)), [f'{exp} a√±os' for exp in experiencias], rotation=45)
        plt.grid(True, alpha=0.3)
        
        # Agregar valores en las barras
        for bar, salario in zip(bars, salarios):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(salarios)*0.01,
                    f'${salario:,.0f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
        
        plt.tight_layout()
        plt.show()
        
        # Casos extremos y limitaciones
        print(f"\n‚ö†Ô∏è  CONSIDERACIONES IMPORTANTES:")
        print(f"   ‚Ä¢ INTERPOLACI√ìN vs EXTRAPOLACI√ìN:")
        print(f"     - Interpolaci√≥n: Predicciones dentro del rango de entrenamiento")
        print(f"     - Extrapolaci√≥n: Predicciones fuera del rango (menos confiables)")
        print(f"   ‚Ä¢ LIMITACIONES DEL MODELO:")
        print(f"     - Asume relaci√≥n lineal constante")
        print(f"     - No considera otros factores (educaci√≥n, ubicaci√≥n, etc.)")
        print(f"     - Puede no ser v√°lido para valores extremos")
        
        # Recomendaciones pr√°cticas
        print(f"\nüíº APLICACI√ìN PR√ÅCTICA:")
        print(f"   ‚Ä¢ El modelo es √∫til para:")
        print(f"     - Estimaciones iniciales de salarios")
        print(f"     - An√°lisis de tendencias salariales")
        print(f"     - Benchmarking en recursos humanos")
        print(f"   ‚Ä¢ Se recomienda:")
        print(f"     - Usar dentro del rango de experiencia conocido")
        print(f"     - Considerar otros factores en decisiones finales")
        print(f"     - Actualizar el modelo con nuevos datos")
        
        print("\n‚úÖ SECCI√ìN 7 COMPLETADA")
        return resultados_predicciones
    
    # =========================================================================
    # SECCI√ìN 8: AN√ÅLISIS Y CONCLUSIONES (10 PUNTOS)
    # =========================================================================
    
    def seccion_8_analisis_conclusiones(self):
        """
        SECCI√ìN 8: An√°lisis y conclusiones 
        Presenta un an√°lisis completo de los resultados y conclusiones del modelo.
        """
        print("\n" + "=" * 60)
        print("üìù SECCI√ìN 8: AN√ÅLISIS Y CONCLUSIONES")
        print("=" * 60)
        
        # Recalcular m√©tricas para el an√°lisis
        mae = mean_absolute_error(self.y_test, self.y_pred)
        mse = mean_squared_error(self.y_test, self.y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(self.y_test, self.y_pred)
        
        print(f"\nüìä RESUMEN EJECUTIVO DEL MODELO:")
        print(f"   ‚Ä¢ Tipo de modelo: Regresi√≥n Lineal Simple")
        print(f"   ‚Ä¢ Variable independiente: A√±os de experiencia")
        print(f"   ‚Ä¢ Variable dependiente: Salario anual")
        print(f"   ‚Ä¢ Tama√±o del dataset: {len(self.df)} observaciones")
        print(f"   ‚Ä¢ Divisi√≥n: {len(self.X_train)} entrenamiento, {len(self.X_test)} prueba")
        
        # An√°lisis de los par√°metros del modelo
        coef = self.modelo.coef_[0]
        intercept = self.modelo.intercept_
        
        print(f"\nüîç AN√ÅLISIS DE LOS PAR√ÅMETROS DEL MODELO:")
        print(f"   ‚Ä¢ Ecuaci√≥n: Salario = {intercept:.2f} + {coef:.2f} √ó Experiencia")
        print(f"   ‚Ä¢ Interpretaci√≥n econ√≥mica:")
        print(f"     - Cada a√±o adicional de experiencia incrementa el salario en ${coef:,.2f}")
        print(f"     - El salario base te√≥rico (0 a√±os) ser√≠a ${intercept:,.2f}")
        print(f"     - La relaci√≥n es {'positiva' if coef > 0 else 'negativa'} y lineal")
        
        # An√°lisis del rendimiento
        print(f"\nüìà AN√ÅLISIS DEL RENDIMIENTO:")
        print(f"   ‚Ä¢ R¬≤ = {r2:.4f}: El modelo explica {r2*100:.1f}% de la variabilidad")
        print(f"   ‚Ä¢ MAE = ${mae:,.2f}: Error promedio de predicci√≥n")
        print(f"   ‚Ä¢ RMSE = ${rmse:,.2f}: Error t√≠pico considerando outliers")
        
        # Evaluaci√≥n de la calidad del ajuste
        if r2 >= 0.8:
            calidad_ajuste = "EXCELENTE"
            color_ajuste = "‚úÖ"
        elif r2 >= 0.6:
            calidad_ajuste = "BUENA"
            color_ajuste = "‚úÖ"
        elif r2 >= 0.4:
            calidad_ajuste = "MODERADA"
            color_ajuste = "‚ö†Ô∏è"
        else:
            calidad_ajuste = "POBRE"
            color_ajuste = "‚ùå"
        
        print(f"\nüéØ EVALUACI√ìN DE LA CALIDAD DEL MODELO:")
        print(f"   {color_ajuste} Calidad del ajuste: {calidad_ajuste}")
        
        # Fortalezas del modelo
        print(f"\nüí™ FORTALEZAS DEL MODELO:")
        fortalezas = []
        
        if r2 >= 0.7:
            fortalezas.append("Alto poder explicativo (R¬≤ ‚â• 0.7)")
        if mae / self.y_test.mean() <= 0.2:
            fortalezas.append("Errores relativamente bajos (MAE ‚â§ 20% del promedio)")
        
        fortalezas.extend([
            "Simplicidad e interpretabilidad",
            "Relaci√≥n clara entre experiencia y salario",
            "Modelo computacionalmente eficiente",
            "F√°cil implementaci√≥n y mantenimiento"
        ])
        
        for i, fortaleza in enumerate(fortalezas, 1):
            print(f"   {i}. {fortaleza}")
        
        # Limitaciones del modelo
        print(f"\n‚ö†Ô∏è  LIMITACIONES DEL MODELO:")
        limitaciones = [
            "Asume relaci√≥n perfectamente lineal",
            "No considera otros factores relevantes (educaci√≥n, ubicaci√≥n, industria)",
            "Sensible a valores at√≠picos",
            "Extrapolaci√≥n fuera del rango puede ser inexacta",
            "No captura posibles efectos no lineales"
        ]
        
        for i, limitacion in enumerate(limitaciones, 1):
            print(f"   {i}. {limitacion}")
        
        # An√°lisis de residuos
        residuos = self.y_test - self.y_pred
        print(f"\nüîç AN√ÅLISIS DE RESIDUOS:")
        print(f"   ‚Ä¢ Media de residuos: ${residuos.mean():.2f} (idealmente ‚âà 0)")
        print(f"   ‚Ä¢ Desviaci√≥n est√°ndar: ${residuos.std():.2f}")
        print(f"   ‚Ä¢ Rango: ${residuos.min():.2f} a ${residuos.max():.2f}")
        
        if abs(residuos.mean()) < rmse * 0.1:
            print(f"   ‚úÖ Los residuos est√°n bien centrados en cero")
        else:
            print(f"   ‚ö†Ô∏è  Los residuos muestran cierto sesgo")
        
        # Recomendaciones para mejoras
        print(f"\nüöÄ RECOMENDACIONES PARA MEJORAS:")
        recomendaciones = [
            "Recopilar m√°s variables explicativas (educaci√≥n, experiencia espec√≠fica, certificaciones)",
            "Aumentar el tama√±o de la muestra para mayor robustez",
            "Explorar modelos no lineales (polinomial, exponencial)",
            "Implementar validaci√≥n cruzada para mejor evaluaci√≥n",
            "Considerar t√©cnicas de regularizaci√≥n si se agregan m√°s variables",
            "Analizar segmentaci√≥n por industria o regi√≥n"
        ]
        
        for i, recomendacion in enumerate(recomendaciones, 1):
            print(f"   {i}. {recomendacion}")
        
        # Aplicaciones pr√°cticas
        print(f"\nüíº APLICACIONES PR√ÅCTICAS DEL MODELO:")
        aplicaciones = [
            "Estimaci√≥n inicial de salarios para nuevas contrataciones",
            "An√°lisis de equidad salarial basada en experiencia",
            "Benchmarking de compensaciones en la industria",
            "Planificaci√≥n de presupuestos de recursos humanos",
            "Herramienta de negociaci√≥n salarial"
        ]
        
        for i, aplicacion in enumerate(aplicaciones, 1):
            print(f"   {i}. {aplicacion}")
        
        # Conclusiones finales
        print(f"\nüéØ CONCLUSIONES FINALES:")
        
        print(f"\n1. VALIDACI√ìN DE LA HIP√ìTESIS:")
        if coef > 0 and r2 >= 0.5:
            print(f"   ‚úÖ Se confirma que existe una relaci√≥n positiva entre experiencia y salario")
            print(f"   ‚úÖ La hip√≥tesis inicial fue correcta")
        else:
            print(f"   ‚ùå La relaci√≥n no es tan clara como se esperaba")
        
        print(f"\n2. UTILIDAD DEL MODELO:")
        if r2 >= 0.6 and mae / self.y_test.mean() <= 0.25:
            print(f"   ‚úÖ El modelo es √∫til para predicciones pr√°cticas")
            print(f"   ‚úÖ Puede ser implementado en aplicaciones reales")
        else:
            print(f"   ‚ö†Ô∏è  El modelo tiene utilidad limitada")
            print(f"   ‚ö†Ô∏è  Se recomienda mejorarlo antes de uso pr√°ctico")
        
        print(f"\n3. APRENDIZAJES CLAVE:")
        print(f"   ‚Ä¢ La regresi√≥n lineal simple es efectiva para relaciones lineales claras")
        print(f"   ‚Ä¢ La experiencia es un predictor significativo del salario")
        print(f"   ‚Ä¢ Los modelos simples pueden ser muy interpretables y √∫tiles")
        print(f"   ‚Ä¢ Siempre es importante validar con datos no vistos")
        
        print(f"\n4. PR√ìXIMOS PASOS:")
        print(f"   ‚Ä¢ Recopilar m√°s datos y variables")
        print(f"   ‚Ä¢ Explorar modelos m√°s complejos")
        print(f"   ‚Ä¢ Implementar en un sistema de producci√≥n")
        print(f"   ‚Ä¢ Monitorear el rendimiento con nuevos datos")
        
        # Visualizaci√≥n final de resumen
        plt.figure(figsize=(16, 10))
        
        # Gr√°fica 1: Modelo completo
        plt.subplot(2, 3, 1)
        plt.scatter(self.X_train, self.y_train, alpha=0.7, s=80, c='blue', 
                   edgecolors='black', linewidth=0.5, label='Entrenamiento')
        plt.scatter(self.X_test, self.y_test, alpha=0.7, s=80, c='red', 
                   edgecolors='black', linewidth=0.5, label='Prueba')
        
        X_all = np.concatenate([self.X_train, self.X_test])
        X_line = np.linspace(X_all.min(), X_all.max(), 100).reshape(-1, 1)
        y_line = self.modelo.predict(X_line)
        plt.plot(X_line, y_line, color='green', linewidth=3, label='Regresi√≥n')
        
        plt.xlabel('A√±os de Experiencia', fontweight='bold')
        plt.ylabel('Salario', fontweight='bold')
        plt.title('Modelo Final de Regresi√≥n Lineal', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Gr√°fica 2: M√©tricas de rendimiento
        plt.subplot(2, 3, 2)
        metricas = ['R¬≤', 'MAE\n(miles)', 'RMSE\n(miles)']
        valores = [r2, mae/1000, rmse/1000]
        colores = ['lightgreen', 'lightblue', 'lightcoral']
        bars = plt.bar(metricas, valores, color=colores, edgecolor='black', linewidth=1)
        plt.ylabel('Valor de la M√©trica', fontweight='bold')
        plt.title('M√©tricas de Rendimiento', fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        for bar, valor, metrica in zip(bars, valores, metricas):
            if 'R¬≤' in metrica:
                texto = f'{valor:.3f}'
            else:
                texto = f'{valor:.1f}k'
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(valores)*0.01,
                    texto, ha='center', va='bottom', fontweight='bold')
        
        # Gr√°fica 3: Distribuci√≥n de errores
        plt.subplot(2, 3, 3)
        plt.hist(residuos, bins=8, alpha=0.7, color='orange', edgecolor='black')
        plt.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Error = 0')
        plt.axvline(x=residuos.mean(), color='blue', linestyle='-', linewidth=2, 
                   label=f'Media: ${residuos.mean():.0f}')
        plt.xlabel('Errores de Predicci√≥n ($)', fontweight='bold')
        plt.ylabel('Frecuencia', fontweight='bold')
        plt.title('Distribuci√≥n de Errores', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Gr√°fica 4: Valores reales vs predichos
        plt.subplot(2, 3, 4)
        plt.scatter(self.y_test, self.y_pred, alpha=0.7, s=100, c='purple', 
                   edgecolors='black', linewidth=0.5)
        min_val = min(self.y_test.min(), self.y_pred.min())
        max_val = max(self.y_test.max(), self.y_pred.max())
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, 
                label='Predicci√≥n perfecta')
        plt.xlabel('Valores Reales ($)', fontweight='bold')
        plt.ylabel('Valores Predichos ($)', fontweight='bold')
        plt.title('Real vs Predicho', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Gr√°fica 5: Resumen textual
        plt.subplot(2, 3, 5)
        plt.axis('off')
        resumen_texto = f"""
RESUMEN EJECUTIVO

üìä DATASET:
‚Ä¢ {len(self.df)} observaciones
‚Ä¢ Variables: Experiencia ‚Üí Salario

ü§ñ MODELO:
‚Ä¢ Tipo: Regresi√≥n Lineal Simple
‚Ä¢ Ecuaci√≥n: y = {intercept:.0f} + {coef:.0f}x

üìà RENDIMIENTO:
‚Ä¢ R¬≤: {r2:.3f} ({r2*100:.1f}% explicado)
‚Ä¢ Error promedio: ${mae:,.0f}
‚Ä¢ Calidad: {calidad_ajuste}

‚úÖ CONCLUSI√ìN:
{'Modelo √∫til para predicciones' if r2 >= 0.6 else 'Modelo necesita mejoras'}
        """
        plt.text(0.05, 0.95, resumen_texto, transform=plt.gca().transAxes,
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.9),
                fontsize=10, verticalalignment='top', fontfamily='monospace')
        
        # Gr√°fica 6: Comparaci√≥n de conjuntos
        plt.subplot(2, 3, 6)
        r2_train = self.modelo.score(self.X_train, self.y_train)
        y_train_pred = self.modelo.predict(self.X_train)
        mae_train = mean_absolute_error(self.y_train, y_train_pred)
        
        conjuntos = ['Entrenamiento', 'Prueba']
        r2_valores = [r2_train, r2]
        mae_valores = [mae_train/1000, mae/1000]
        
        x = np.arange(len(conjuntos))
        width = 0.35
        
        bars1 = plt.bar(x - width/2, r2_valores, width, label='R¬≤', color='lightgreen', 
                       edgecolor='black', linewidth=1)
        bars2 = plt.bar(x + width/2, mae_valores, width, label='MAE (miles)', color='lightblue', 
                       edgecolor='black', linewidth=1)
        
        plt.xlabel('Conjunto de Datos', fontweight='bold')
        plt.ylabel('Valor de M√©trica', fontweight='bold')
        plt.title('Comparaci√≥n Entrenamiento vs Prueba', fontweight='bold')
        plt.xticks(x, conjuntos)
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        print("\n" + "=" * 80)
        print("üéâ AN√ÅLISIS COMPLETO DE REGRESI√ìN LINEAL FINALIZADO")
        print("=" * 80)
        print(f"‚úÖ Todas las secciones completadas exitosamente")
        print(f"‚úÖ Modelo entrenado y validado")
        print(f"‚úÖ Predicciones realizadas")
        print(f"‚úÖ An√°lisis y conclusiones presentadas")
        
        print("\n‚úÖ SECCI√ìN 8 COMPLETADA")
        return True
    
regresionLinealSalarios = RegresionLinealSalarios()